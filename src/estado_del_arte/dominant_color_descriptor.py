# -*- coding: utf-8 -*-
"""Dominant Color Descriptor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ql1lgSMkSmeJgSLxyg7xq8pgcN3XlqzW
"""

# Basado en: https://gist.github.com/skt7/71044f42f9323daec3aa035cd050884e
#from google.colab import drive
#drive.mount('/content/drive')

# Librerías
import sys
import numpy as np
import cv2
from sklearn.cluster import KMeans
from sklearn.svm import SVC
from datetime import datetime
import csv
from sklearn.multiclass import OneVsRestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier

"""# Parámetros"""

NO_CLUSTERS = 4

base_datos_param = sys.argv[1]
print("Base de datos parametro:", base_datos_param)
PATH_BASE = "../databases/" + base_datos_param + "/"
# Clasificador
CLASSIFIER = sys.argv[2]
print("Clasificador parametro:", CLASSIFIER)
# random_state
RANDOM_STATE = int(sys.argv[3])

"""# Funciones"""

# Lectura de imágenes
def read_images(txt): # txt: archivo.txt
  labels = np.array([])

  # Lectura de nombres de archivos de entrenamiento
  path_base = PATH_BASE
  f = open(path_base + "000/" + txt,"r")
  lineas = f.readlines()

  imagenes = []
  for i in range(1, len(lineas)):
    nombreArchivo = lineas[i].split()[0]
    labels = np.append(labels, lineas[i].split()[1])
    path = path_base + "images/" + nombreArchivo
    img = cv2.imread(path)
    imagenes.append(img)
  return imagenes, labels # retorna un array de imágenes y un array de nombre de clases

# Quantization
diccionario_normalizadoH = {}
diccionario_normalizadoS = {}
diccionario_normalizadoV = {}
'''
Documentation OpenCV:
For HSV, hue range is [0,179], saturation range is [0,255], and value range is [0,255].
Different software use different scales.
So if you are comparing OpenCV values with them, you need to normalize these ranges.
'''
def getH(n):
  '''
  PAPER:
  Total: [0, 360]
  0 [316, 20)
  1 [20, 40)
  2 [40, 75)
  3 [75,155)
  4 [155,190)
  5 [190, 270)
  6 [270, 295)
  7 [295,316)
  Para OpenCV:
  Total: [0,179]
  316 : 157.12222222222223
  20 : 9.944444444444445
  40 : 19.88888888888889
  75 : 37.29166666666667
  155 : 77.06944444444444
  190 : 94.47222222222223
  270 : 134.25
  295 : 146.68055555555554
  '''
  return_value = None
  if (n >= 0 and n < diccionario_normalizadoH[20]) or (n >= diccionario_normalizadoH[316] and n <= diccionario_normalizadoH[360]):
    return_value = 0
  elif n >= diccionario_normalizadoH[20] and n < diccionario_normalizadoH[40]:
    return_value = 1
  elif n >= diccionario_normalizadoH[40] and n < diccionario_normalizadoH[75]:
    return_value = 2
  elif n >= diccionario_normalizadoH[75] and n < diccionario_normalizadoH[155]:
    return_value = 3
  elif n >= diccionario_normalizadoH[155] and n < diccionario_normalizadoH[190]:
    return_value = 4
  elif n >= diccionario_normalizadoH[190] and n < diccionario_normalizadoH[270]:
    return_value = 5
  elif n >= diccionario_normalizadoH[270] and n < diccionario_normalizadoH[295]:
    return_value = 6
  elif n >= diccionario_normalizadoH[295] and n < diccionario_normalizadoH[316]:
    return_value = 7

  return return_value

def getS(n):
  '''
  PAPER:
  Total : [0, 1]
  0 [0,0.2]
  1 (0.2,0.7]
  2 (0.7,1]
  Para OpenCV:
  Total: [0,255]
  '''
  if n >= diccionario_normalizadoS[0] and n <= diccionario_normalizadoS[0.2]:
    return 0
  elif n > diccionario_normalizadoS[0.2] and n <= diccionario_normalizadoS[0.7]:
    return 1
  elif n > diccionario_normalizadoS[0.7] and n <= diccionario_normalizadoS[1]:
    return 2

def getV(n):
  '''
  PAPER:
  Total: [0, 1]
  0 [0, 0.2]
  1 (0.2,0.7]
  2 (0.7,1]
  Para OpenCV:
  Total: [0,255]
  '''
  if n >= diccionario_normalizadoV[0] and n <= diccionario_normalizadoV[0.2]:
    return 0
  elif n > diccionario_normalizadoV[0.2] and n <= diccionario_normalizadoV[0.7]:
    return 1
  elif n > diccionario_normalizadoV[0.7] and n <= diccionario_normalizadoV[1]:
    return 2

def quantizeHSVImage(img):
  h,s,v = cv2.split(img)

  #print('H')
  limites_paper = [316, 20, 40, 75, 155, 190, 270, 295, 360]
  for a in limites_paper:
    diccionario_normalizadoH[a] = (a/360)*179
  quantizedH = np.vectorize(getH)(h)

  #print('S')
  limites_paperS = [0, 0.2, 0.7, 1]
  for a in limites_paperS:
    diccionario_normalizadoS[a] = (a)*255
  quantizedS = np.vectorize(getS)(s)

  #print('V')
  limites_paperV = [0, 0.2, 0.7, 1]
  for a in limites_paperV:
    diccionario_normalizadoV[a] = (a)*255
  quantizedV = np.vectorize(getV)(v)

  quantizedImage = cv2.merge([quantizedH, quantizedS, quantizedV])
  return quantizedImage

def dcd(img):
  #convert to HSV from BGR
  img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

  # Quantization
  img = quantizeHSVImage(img)

  cantidad_pixeles = img.shape[0] * img.shape[1]

  #reshaping to a list of pixels
  img_reshape = img.reshape((img.shape[0] * img.shape[1], img.shape[2]))

  #using k-means to cluster pixels
  kmeans = KMeans(n_clusters = NO_CLUSTERS, random_state=RANDOM_STATE)
  kmeans.fit(img_reshape)

  #the cluster centers are our dominant colors.
  dominant_colors = kmeans.cluster_centers_

  cant_images_por_cluster = np.zeros(NO_CLUSTERS)

  for i in range(len(img_reshape)):
    feature = img_reshape[i]
    feature = feature.reshape(1, -1)
    # A qué cluster pertenece
    idx = kmeans.predict(feature)
    cant_images_por_cluster[idx] += 1

  #print('--COLORES DOMINANTES:')
  #print(dominant_colors)
  #print('--CANTIDAD DE IMAGENES POR COLOR DOMINANTE / CLUSTER:')
  #print(cant_images_por_cluster)

  prob_por_cluster = cant_images_por_cluster / cantidad_pixeles

  #print('--PROBABILIDAD DE CADA COLOR DOMINANTE / CLUSTER')
  #print(prob_por_cluster)

  descriptor_final = []

  for i in range(len(dominant_colors)):
    descriptor = np.zeros(4) # 3 dimensions + 1 probability
    for j in range(len(dominant_colors[i])):
      descriptor[j] = dominant_colors[i][j]
    descriptor[len(dominant_colors[i])] = prob_por_cluster[i]
    descriptor_final.append(descriptor)

  #save labels
  #labels = kmeans.labels_
        
  #returning
  #print("---DESCRIPTOR:")
  #print(descriptor_final)
  descriptor_final = np.asarray(descriptor_final)
  descriptor_final = descriptor_final.reshape(descriptor_final.shape[0] * descriptor_final.shape[1])
  return descriptor_final

"""# Ejecución"""

# Lectura de imágenes
imagenes_entrenamiento, labels_entrenamiento =  read_images("train.txt")
print("Cantidad de imágenes de entrenamiento:",  len(imagenes_entrenamiento))
imagenes_prueba, labels_prueba =  read_images("test.txt")
print("Cantidad de imágenes de prueba:",  len(imagenes_prueba))

# TRAINING
print("ENTRENAMIENTO...")
histogramas_entrenamiento = []
for imagen in imagenes_entrenamiento:
  resultado = dcd(imagen)
  histogramas_entrenamiento.append(resultado)

print("Entrenando clasificador...")
if CLASSIFIER == 'ovsr':
  svm = OneVsRestClassifier(SVC(kernel = 'linear'))
  svm.fit(histogramas_entrenamiento, labels_entrenamiento)
  _classifier = svm
elif CLASSIFIER == 'svc':
  svm = SVC(kernel = 'linear')
  svm.fit(histogramas_entrenamiento, labels_entrenamiento)
  _classifier = svm
elif CLASSIFIER == 'knn':
  n_neighbors = 1
  knn = KNeighborsClassifier(n_neighbors)
  knn.fit(histogramas_entrenamiento, labels_entrenamiento)
  _classifier = knn
elif CLASSIFIER == 'rfc':
  rfc = RandomForestClassifier(random_state=0)
  rfc.fit(histogramas_entrenamiento, labels_entrenamiento)
  _classifier = rfc

# PRUEBA
print("PRUEBA...")
histogramas_prueba = []
for imagen in imagenes_prueba:
  resultado = dcd(imagen)
  histogramas_prueba.append(resultado)

#SVC
predicciones = _classifier.predict(histogramas_prueba)

# Exactitud
from sklearn.metrics import accuracy_score
print(accuracy_score(labels_prueba, predicciones))

print("Guardar resultados en archivos...")
now = datetime.now()
FECHA_HORA = str(now.year) + '-' + str(now.month) + '-' + str(now.day) + '-' + str(now.hour)  + str(now.minute) + str(now.second)
CSV_PATH = "../resultados/DCD_corregido_" + str(RANDOM_STATE) + "_" + str(NO_CLUSTERS) + "_" + base_datos_param + '_' + FECHA_HORA +  "_" + CLASSIFIER + ".csv"

titulos = ["Exactitud"] # Para imprimir en csv
with open(CSV_PATH,'w') as f:
  w = csv.writer(f)
  w.writerow(titulos)
  w.writerow([accuracy_score(labels_prueba, predicciones)])

# guardar vectores de caracteristicas
TRAIN_PATH = "../resultados/DCD_corregido_" + str(RANDOM_STATE) + "_" + str(NO_CLUSTERS) + "_" + base_datos_param + "_train_" + FECHA_HORA + "_" + CLASSIFIER + ".csv"
TEST_PATH = "../resultados/DCD_corregido_" + str(RANDOM_STATE) + "_" + str(NO_CLUSTERS) + "_" + base_datos_param + "_test_" + FECHA_HORA + "_" + CLASSIFIER + ".csv"

with open(TRAIN_PATH,'w+') as f:
  w = csv.writer(f)
  titulos = ["CLASE"] + list(range(len(histogramas_entrenamiento[0])))
  w.writerow(titulos)
  for i in range(len(histogramas_entrenamiento)):
    fila = []
    fila.append(labels_entrenamiento[i])
    fila = fila + list(histogramas_entrenamiento[i])
    w.writerow(fila)

with open(TEST_PATH,'w+') as f:
  w = csv.writer(f)
  titulos = ["CLASE"] + list(range(len(histogramas_prueba[0])))
  w.writerow(titulos)
  for i in range(len(histogramas_prueba)):
    fila = []
    fila.append(labels_prueba[i])
    fila = fila + list(histogramas_prueba[i])
    w.writerow(fila)

print("Terminado!!")
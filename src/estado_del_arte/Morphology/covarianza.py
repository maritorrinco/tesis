# -*- coding: utf-8 -*-
"""Covarianza.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1la3Mjq8bUyz1UE9k1leesGp-woWz8Bdg
"""

from google.colab import drive
drive.mount('/content/drive')

import cv2 
import csv
import numpy as np
import statistics as stats
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.multiclass import OneVsRestClassifier
from sklearn.metrics import accuracy_score
from scipy.spatial import distance
from datetime import datetime
import sys

PATH_BASE = "drive/My Drive/Colab Notebooks/Outex_TC_00013/"

# Resultados en:
now = datetime.now()
FECHA_HORA = str(now.year) + '-' + str(now.month) + '-' + str(now.day) + '-' + str(now.hour)  + str(now.minute) + str(now.second)
CSV_PATH = "drive/MyDrive/Colab Notebooks/resultados/resultados" + FECHA_HORA + ".csv"

DISTANCES = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]
#DISTANCES = [1]
#ANGLES = [0]
ANGLES = [0, 45, 90, 135]

# 0: grayscale
# 1: rgb marginal
# 2: rgb vectorial
COVARIANCE_TYPE = 1

MEASURE = "VOLUME"
#MEASURE = "ENERGY"
#MEASURE = "VARIANCE"

#CLASSIFIER = "SVM"
CLASSIFIER = "K-NN"

def leer_imagenes(txt): # txt: archivo.txt
  labels = np.array([])

  # Lectura de nombres de archivos de entrenamiento
  path_base = PATH_BASE
  f = open(path_base + "000/" + txt,"r")
  lineas = f.readlines()

  imagenes = []
  for i in range(1, len(lineas)):
    nombreArchivo = lineas[i].split()[0]
    labels = np.append(labels, lineas[i].split()[1])
    path = path_base + "images/" + nombreArchivo
    img = cv2.imread(path, 0) if COVARIANCE_TYPE == 0 else cv2.imread(path)
    
    imagenes.append(img)
  return imagenes, labels # retorna un array de imágenes y un array de nombre de clases

def volumen(img):
  return np.sum(img)

def energia(img):
  nrg = 0
  width, height = img.shape
  
  for v in range(height):
    for u in range(width):
      nrg += img[u][v]**2
    
  return nrg

# Medida: Varianza
def varianza(imagen):
  flat_list = [item for sublist in imagen for item in sublist]
  cardE = len(flat_list)

  media = stats.mean(flat_list)

  varianza = 0
  for p in flat_list:
    varianza = varianza + (p - media)**2

  varianza = (1/cardE) * varianza

  return varianza

def get_structuring_element(distance, angle):  
  if angle == 0:
    point_2 = [distance*1, 0]
  elif angle == 45:
    point_2 = [distance*1, distance*1]
  elif angle == 90:
    point_2 = [0, distance*1]
  elif angle == 135:
    point_2 = [distance*(-1), distance*1]

  se = { 'p1': [0, 0], 'p2': point_2 }

  return se
  
def get_list_structuring_element(distances, angles):
  list_se = []
  for d in distances:
    for a in angles:
      list_se.append(get_structuring_element(d,a))

  return list_se

def mininum_single_channel(image, se): #se: elemento estructural
  width, height = image.shape

  img_processed = image

  for v in range(height):
    for u in range(width):
      pval_min = 255

      for p in se:
        px = se[p][0] + u
        py = se[p][1] + v

        if px >= width or py >= height or px < 0 or py < 0:
          continue
        
        pval = img_processed[px][py]
                    
        #busqueda del minimo  
        if pval_min > pval:
          pval_min = pval	
                    
      img_processed[u][v] = pval_min
          
  return img_processed
  
def mininum_single_channel_vectorial(image, se): #se: elemento estructural
  width, height, channels = image.shape

  img_processed = image

  for v in range(height):
    for u in range(width):
      distance_min = sys.float_info.max
      concrete_min = 0

      for p in se:
        px = se[p][0] + u
        py = se[p][1] + v

        if px >= width or py >= height or px < 0 or py < 0:
          continue
          
        pval = image[px][py]

        distance_val = distance.euclidean(pval, (0, 0, 0))

                      
        #busqueda del minimo  
        if distance_min > distance_val:
          distance_min = distance_val
          concrete_min = pval;	

                      
      img_processed[u][v] = concrete_min
          
  return img_processed

def covariance_grayscale(imagenes, list_of_se, medida):
  features = []

  for i in range(len(imagenes)):
    image = imagenes[i]
    vol_img_original = medida(image)

    res_covarianza = []

    for se in list_of_se:
      erosion = mininum_single_channel(image, se)
      vol_img_closing = medida(erosion)
      division_volumenes = vol_img_closing / vol_img_original
      res_covarianza.append(division_volumenes)
    features.append(res_covarianza)

  return features

def covariance_marginal(imagenes, list_of_se, medida):
  features = []
  
  for i in range(len(imagenes)):
    image = imagenes[i]
    try:
      b,g,r = cv2.split(image)

      vol_img_original = [medida(r), medida(g), medida(b)]

      res_covarianza = []
      for se in list_of_se:
        for index, channel in enumerate([r,g,b]):
          erosion = mininum_single_channel(channel, se)
          vol_img_closing = medida(erosion)
          division_volumenes = vol_img_closing / vol_img_original[index]
          res_covarianza.append(division_volumenes)
      features.append(res_covarianza)
    except Exception as e:
      print(e)
  return features

def covariance_vectorial(imagenes, list_of_se, medida):
  features = []
  
  for i in range(len(imagenes)):
    image = imagenes[i]
    try:
      b,g,r = cv2.split(image)

      vol_img_original = [medida(r), medida(g), medida(b)]

      res_covarianza = []
      for se in list_of_se:
        erosion = mininum_single_channel_vectorial(image, se)
        erosion_b, erosion_g, erosion_r = cv2.split(erosion)
        erosions = [erosion_r, erosion_g, erosion_b]
        for index, channel in enumerate([r,g,b]):
          vol_img_closing = medida(erosions[index])
          division_volumenes = vol_img_closing / vol_img_original[index]
          res_covarianza.append(division_volumenes)
      features.append(res_covarianza)
    except Exception as e:
      print(e)

  return features

def entrenamiento(imagenes_entrenamiento, labels_entrenamiento, list_of_se):
  medida = volumen
  if MEASURE == "ENERGY":
    medida = energia
  elif MEASURE == "VARIANCE":
    medida = varianza

  if COVARIANCE_TYPE == 0:
    features_imagenes = covariance_grayscale(imagenes_entrenamiento, list_of_se, medida)
  elif COVARIANCE_TYPE == 1:
    features_imagenes = covariance_marginal(imagenes_entrenamiento, list_of_se, medida)
  elif COVARIANCE_TYPE == 2:
    features_imagenes = covariance_vectorial(imagenes_prueba, list_of_se, medida)
  
  if CLASSIFIER == "SVM":
    classifier = SVC(kernel = 'linear')
  elif CLASSIFIER == "K-NN":
    classifier = KNeighborsClassifier(n_neighbors = 1)
  
  classifier.fit(features_imagenes, labels_entrenamiento)
  
  return classifier

def prueba(imagenes_prueba, labels_prueba, classifier, list_of_se):
  medida = volumen
  if MEASURE == "ENERGY":
    medida = energia
  elif MEASURE == "VARIANCE":
    medida = varianza

  # Extracción de features de las imágenes de prueba
  if COVARIANCE_TYPE == 0:
    features_imagenes = covariance_grayscale(imagenes_prueba, list_of_se, medida)
  elif COVARIANCE_TYPE == 1:
    features_imagenes = covariance_marginal(imagenes_prueba, list_of_se, medida)
  elif COVARIANCE_TYPE == 2:
    features_imagenes = covariance_vectorial(imagenes_prueba, list_of_se, medida)

  # Predicciones utilizando SVM o K-NN
  predicciones = classifier.predict(features_imagenes)

  # Resultados
  exactitud = accuracy_score(labels_prueba, predicciones)

  with open(CSV_PATH,'w') as f:
    w = csv.writer(f)
    w.writerow(["covariance","measure","exactitud"])
    w.writerow([COVARIANCE_TYPE, MEASURE, exactitud])

  print ('Exactitud: %0.3f' % exactitud)
  return exactitud

def main(imagenes_entrenamiento, labels_entrenamiento, imagenes_prueba, labels_prueba):
  list_of_structuring_elements = get_list_structuring_element(DISTANCES, ANGLES)

  print("Entrenamiento...")
  classifier = entrenamiento(imagenes_entrenamiento, labels_entrenamiento, list_of_structuring_elements)

  print("Prueba...")
  exactitud = prueba(imagenes_prueba, labels_prueba, classifier, list_of_structuring_elements)
  return exactitud

#Leer imágenes de entrenamiento (una sola vez)
print("Lectura de imágenes de entrenamiento....")
imagenes_entrenamiento, labels_entrenamiento =  leer_imagenes("train.txt")
print("Cantidad de imágenes de entrenamiento:",  len(imagenes_entrenamiento))

# Lectura de imágenes de prueba (una sola vez)
print("Lectura de imágenes de prueba....")
imagenes_prueba, labels_prueba =  leer_imagenes("test.txt")
print("Cantidad de imágenes de prueba:",  len(imagenes_prueba))



exactitud = main(imagenes_entrenamiento, labels_entrenamiento, imagenes_prueba, labels_prueba)

print(exactitud)
# -*- coding: utf-8 -*-
"""RGB Pixel N-grams.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SERPqrWPdXo4QKfrj3857P5JbuiKW1a2
"""

# -*- coding: utf-8 -*-
"""RGB Pixel N-grams.ipynb

Automatically generated by Colaboratory.

Orden de los parámetros bash:
python3 vectores-21.py base_de_datos metodo rango v1 v2 clasificador
python3 vectores-21.py Outex_TC_00013 1 12 2 1 svc
"""

from google.colab import drive
drive.mount('/content/drive')

# Librerías
import sys
from skimage.util import view_as_windows
import cv2
from sklearn.feature_extraction.text import CountVectorizer
import numpy as np
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from itertools import product
from termcolor import colored
import csv
import math
import itertools
import operator
from scipy.sparse import csr_matrix
from datetime import datetime
from sklearn.neighbors import KNeighborsClassifier
import scipy.sparse
from sklearn.ensemble import RandomForestClassifier
import sklearn
from sklearn.multiclass import OneVsRestClassifier


################################################################ PARAMS ####################################################################################
IS_COLAB = True
dbase = ""
PATH_BASE = "drive/My Drive/Colab Notebooks/Outex_TC_00013/"
# Outex 13: drive/My Drive/Colab Notebooks/Outex_TC_00013/
# Brodatz: drive/My Drive/Colab Notebooks/Brodatz_dividido/
# Vistex: drive/My Drive/Colab Notebooks/Vistex_dividido/
# Curet: drive/My Drive/Colab Notebooks/Curet_modificado/
if len(sys.argv) > 1 and not(IS_COLAB):
  dbase = sys.argv[1]
  print("Base de datos parametro:", dbase)
  PATH_BASE = "drive/My Drive/Colab Notebooks/" + dbase + "/"


METHOD = 1
# Parametro desde linea de comandos:
if len(sys.argv) > 2 and not(IS_COLAB):
  METHOD = int(sys.argv[2])
  print("Metodo parametro:", METHOD)
# Implementación 1: 1
# Implementación 2: 2


RANGES = [8]
# Parametro desde linea de comandos:
if len(sys.argv) > 3 and not(IS_COLAB):
  RANGES = [int(sys.argv[3])]
  print("Rango parametro:", sys.argv[3])
STEPS = [1]


WINDOWS = [ [(2, 2)] ]
#WINDOWS = None
# Parametros desde linea de comandos:
if len(sys.argv) > 5 and not(IS_COLAB):
  WINDOWS = [ [ (int(sys.argv[4]), int(sys.argv[5]) )] ]
  print("Dimension parametro:", int(sys.argv[4]) ,'x',  int(sys.argv[5]) )
# Dimensiones mínima y máxima (para filas y columnas) de las ventanas
MIN_DIMENSION = 1
MAX_DIMENSION = 4
INCREASE_BY = 2
# Cantidad mínima de tamaños de ventanas diferentes
MIN_COMBINED_WINDOWS = 1
# Cantidad máxima de tamañosd de ventanas diferentes
MAX_COMBINED_WINDOWS = 2


CLASSIFIER = 'ovsr'
# Posibles valores: rfc; svc; knn
# Parametro desde linea de comandos:
if len(sys.argv) > 6 and not(IS_COLAB):
  CLASSIFIER = sys.argv[6]
  print("Clasificador parametro:", CLASSIFIER)



############################################################ NOMBRE DE ARCHIVO - DONDE SE GUARDA EL RESULTADO ##################################################
now = datetime.now()
FECHA_HORA = str(now.year) + '-' + str(now.month) + '-' + str(now.day) + '-' + str(now.hour)  + str(now.minute) + str(now.second)
CSV_PATH = str(METHOD) + "_" + dbase + "_" + FECHA_HORA + "_" + CLASSIFIER + ".csv"


################################################################### CONSTANTS #######################################################################################3
ALPHA = chr(0x03B1) # α - red
BETA = chr(0x03B2) # β - green
GAMMA = chr(0x0263) # γ - blue


###############################################################################3# Funtions #############################################################################3
def generate_configurations():
  try:

    if WINDOWS is None and (MIN_DIMENSION > 0 and MAX_DIMENSION > 0 and INCREASE_BY > 0 and MIN_COMBINED_WINDOWS > 0 and MAX_COMBINED_WINDOWS > 0):
      dim_ventanas = {
        'r': list(range(MIN_DIMENSION, MAX_DIMENSION + 1, INCREASE_BY)),
        'c': list(range(MIN_DIMENSION, MAX_DIMENSION + 1, INCREASE_BY))
      }

      dim_ventanas_names, dim_ventanas_values = zip(*dim_ventanas.items())
      # Extracción de combinaciones de Ventanas
      tam_ventanas = [dict(zip(dim_ventanas_names, h)) for h in product(*dim_ventanas_values)]

      win_combinations = []

      for L in range(MIN_COMBINED_WINDOWS, MAX_COMBINED_WINDOWS + 1):
          for subconjunto in itertools.combinations(tam_ventanas, L):
            win_combinations.append(subconjunto)

      windows = []
      for comb in win_combinations:
        comb_array = []
        for w in comb:
          row = w.get("r")
          col = w.get("c")
          comb_array.append((row, col))
        windows.append(comb_array)

    elif WINDOWS is not None:
      windows = WINDOWS

    else:
      print("Verify params: all params should be > 0.")
      return None

    parametros = {'range': RANGES,
                  'windows': windows,
                  'step': STEPS}
    param_names, param_values = zip(*parametros.items())
    params_set = [dict(zip(param_names, h)) for h in product(*param_values)]

    return params_set

  except Exception as e:
    print("Verify params:", e)


def generate_characters():
  characters = ""

  start = 0x0021 # desde !
  end = 0x007E # hasta ~
  for i in range(start, end + 1):
    characters = characters+chr(i)

  start_1 = 0x00C0 # desde À
  end_1 = 0x00FF # hasta ÿ
  for i in range(start_1, end_1 + 1):
    characters = characters+chr(i)

  start_2 = 0x0100 # Ā
  end_2 = 0x0161 # š
  for i in range(start_2, end_2 + 1):
    characters = characters+chr(i)

  return characters


def get_alphabet_size(letras, _range):
  p1 = 0
  p2 = 0
  valoresPorLetra = {} # Para mostrar
  for i in range(len(letras)):
    p2 = p1 + (_range - 1)
    if p2 > 255:
      p2 = 255
    valoresPorLetra[letras[i]] = list(range(p1, p2 + 1))
    p1 = p1 + _range

  tamAlfabeto = 0
  for i in range(len(valoresPorLetra)):
    array_grises = valoresPorLetra.get(letras[i])
    if len(array_grises) == 0:
      break
    tamAlfabeto += 1
  return tamAlfabeto


def read_images(txt): # txt: archivo.txt
  labels = np.array([])

  # Lectura de nombres de archivos de entrenamiento
  path_base = PATH_BASE
  f = open(path_base + "000/" + txt,"r")
  lineas = f.readlines()

  imagenes = []
  for i in range(1, len(lineas)):
    nombreArchivo = lineas[i].split()[0]
    labels = np.append(labels, lineas[i].split()[1])
    path = path_base + "images/" + nombreArchivo
    img = cv2.imread(path)
    imagenes.append(img)
  return imagenes, labels # retorna un array de imágenes y un array de nombre de clases


def get_character(n, characters, _range):
  # n es el valor del pixel
  indice = int(n // _range)
  return characters[indice]


def extract_patches(image, patch_size, step):
  view = view_as_windows(image, patch_size, step) # crea ventanas cuadradas
  return view.reshape(-1,patch_size[0]*patch_size[1]) # convierte cada ventana en un vector


def method1(imagenes, letras, windows, step, _range):
  cantidad_imagenes = len(imagenes)

  palabras_por_imagen = []
  # Variables utilizadas para calcular posteriormente cantidades / tasas (para añadir nuevos valores al vector de características)
  palabras_por_imagen_B = []
  palabras_por_imagen_G = []
  palabras_por_imagen_R = []

  # Recorrer todas las imágenes
  for imagen in range(cantidad_imagenes):
    palabras_por_imagen.append('')
    palabras_por_imagen_B.append('')
    palabras_por_imagen_G.append('')
    palabras_por_imagen_R.append('')

    # Dividir la imagen en sus tres canales
    b,g,r = cv2.split(imagenes[imagen])

    # Generar palabras una ventana a la vez
    for VENTANA in windows:
      palabras = []
      palabras_B = []
      palabras_G = []
      palabras_R = []

      # Extracción de las ventanas de la imagen (por cada canal)
      # AZUL
      ventanas_b = extract_patches(b, VENTANA, step)
      # VERDE
      ventanas_g = extract_patches(g, VENTANA, step)
      # ROJO
      ventanas_r = extract_patches(r, VENTANA, step)

      longitud_ventanas = len(ventanas_b) # Misma longitud para todas las ventanas
      # Por cada ventana extraída
      for i in range(longitud_ventanas):
        palabras.append('')
        palabras_B.append('')
        palabras_G.append('')
        palabras_R.append('')

        for j in range(len(ventanas_b[i])): # por cada pixel en la ventana B
          palabras_B[i] = palabras_B[i] + get_character(ventanas_b[i][j], letras, _range)
          palabras[i] = palabras[i] + get_character(ventanas_b[i][j], letras, _range) # se obtiene el caracter que representa al valor de gris de ese pixel

        for j in range(len(ventanas_g[i])): # por cada pixel en la ventana G
          palabras_G[i] = palabras_G[i] + get_character(ventanas_g[i][j], letras, _range)
          palabras[i] = palabras[i] + get_character(ventanas_g[i][j], letras, _range) # se obtiene el caracter que representa al valor de gris de ese pixel

        for j in range(len(ventanas_r[i])): # por cada pixel en la ventana R
          palabras_R[i] = palabras_R[i] + get_character(ventanas_r[i][j], letras, _range)
          palabras[i] = palabras[i] + get_character(ventanas_r[i][j], letras, _range) # se obtiene el caracter que representa al valor de gris de ese pixel

      # Concatenar en la posición "imagen" correspondiente dentro de los arrays de palabras
      if len(palabras_por_imagen[imagen]) > 0:
        palabras_por_imagen[imagen] = palabras_por_imagen[imagen] + ' ' + ' '.join(palabras) # corpus para el CountVectorizer. Una lista de strings, donde las palabras están separadas por espacios
        palabras_por_imagen_B[imagen] = palabras_por_imagen_B[imagen] + ' ' + ' '.join(palabras_B)
        palabras_por_imagen_G[imagen] = palabras_por_imagen_G[imagen] + ' ' + ' '.join(palabras_G)
        palabras_por_imagen_R[imagen] = palabras_por_imagen_R[imagen] + ' ' + ' '.join(palabras_R)
      else:
        palabras_por_imagen[imagen] = ' '.join(palabras)
        palabras_por_imagen_B[imagen] = ' '.join(palabras_B)
        palabras_por_imagen_G[imagen] = ' '.join(palabras_G)
        palabras_por_imagen_R[imagen] = ' '.join(palabras_R)

  return palabras_por_imagen, palabras_por_imagen_B, palabras_por_imagen_G, palabras_por_imagen_R


def method2(imagenes, letras, windows, step, _range):
  cantidad_imagenes = len(imagenes)
  palabras_por_imagen = []
  palabras_por_imagen_R = []
  palabras_por_imagen_G = []
  palabras_por_imagen_B = []

  for imagen in range(cantidad_imagenes):
    palabrasR = [] # palabras del plano R
    palabrasG = [] # palabras del plano G
    palabrasB = [] # palabras del plano B

    b,g,r = cv2.split(imagenes[imagen])
    for v in range(len(windows)):
      ventanasR = extract_patches(r, windows[v], step) # se extraen las ventanas de la imagen en el plano R
      ventanasG = extract_patches(g, windows[v], step) # se extraen las ventanas de la imagen en el plano G
      ventanasB = extract_patches(b, windows[v], step) # se extraen las ventanas de la imagen en el plano B
      palabras_length=len(palabrasB)
      for i in range(len(ventanasB)): # por cada ventana de la imagen
        palabrasR.append("")
        palabrasG.append("")
        palabrasB.append("")
        i_index = i+palabras_length
        for j in range(len(ventanasB[i])): # por cada pixel en la ventana
          palabrasR[i_index] = palabrasR[i_index] + get_character(ventanasR[i][j], letras, _range) # se obtiene el caracter que representa al valor de gris de ese pixel
          palabrasG[i_index] = palabrasG[i_index] + get_character(ventanasG[i][j], letras, _range) # se obtiene el caracter que representa al valor de gris de ese pixel
          palabrasB[i_index] = palabrasB[i_index] + get_character(ventanasB[i][j], letras, _range) # se obtiene el caracter que representa al valor de gris de ese pixel
        palabrasR[i_index]=palabrasR[i_index] +  ALPHA
        palabrasG[i_index]=palabrasG[i_index] + BETA
        palabrasB[i_index]=palabrasB[i_index] + GAMMA

    palabras_por_imagen.append(' '.join(palabrasR) +" "+ ' '.join(palabrasG) +" "+ ' '.join(palabrasB)) # corpus para el CountVectorizer. Una lista de strings, donde las palabras están separadas por espacios
    palabras_por_imagen_R.append(' '.join(palabrasR))
    palabras_por_imagen_G.append(' '.join(palabrasG))
    palabras_por_imagen_B.append(' '.join(palabrasB))

  return palabras_por_imagen, palabras_por_imagen_R, palabras_por_imagen_G, palabras_por_imagen_B


def extract_words(imagenes, characters, windows, step, _range):
  if METHOD == 1:
    palabras_por_imagen, palabras_por_imagen_B, palabras_por_imagen_G, palabras_por_imagen_R = method1(imagenes, characters, windows, step, _range)
  elif METHOD == 2:
    palabras_por_imagen, palabras_por_imagen_B, palabras_por_imagen_G, palabras_por_imagen_R = method2(imagenes, characters, windows, step, _range)
  return palabras_por_imagen, palabras_por_imagen_B, palabras_por_imagen_G, palabras_por_imagen_R


def train(imagenes, labels_entrenamiento, characters, windows, step, _range):
  palabras_por_imagen, palabras_por_imagen_B, palabras_por_imagen_G, palabras_por_imagen_R = extract_words(imagenes, characters, windows, step, _range)
  print ('palabras_por_imagen', palabras_por_imagen[0])

  #Generar diccionario
  vectorizer = CountVectorizer(token_pattern=r"(?u)[" + characters + ALPHA + BETA + GAMMA + "]+", lowercase=False) # Nos indica con qué caracteres están conformadas las palabras.
  X = vectorizer.fit_transform(palabras_por_imagen)
  print("despues de countvectorizer")
  diccionario = vectorizer.get_feature_names() # diccionario

  tam_diccionario = len(diccionario) # Tamaño del diccionario / alfabeto

  # Entrenar clasificador
  print("antes de entrenar")

  if CLASSIFIER == 'svc':
    svm = SVC(kernel = 'linear')
    svm.fit(X, labels_entrenamiento)
    _classifier = svm
  elif CLASSIFIER == 'knn':
    n_neighbors = 1
    knn = KNeighborsClassifier(n_neighbors)
    knn.fit(X, labels_entrenamiento)
    _classifier = knn
  elif CLASSIFIER == 'rfc':
    rfc = RandomForestClassifier(random_state=0)
    rfc.fit(X, labels_entrenamiento)
    _classifier = rfc
  elif CLASSIFIER == 'ovsr':
    ovsr = OneVsRestClassifier(SVC(kernel = 'linear'))
    ovsr.fit(X, labels_entrenamiento)
    _classifier = ovsr

  return _classifier, vectorizer, tam_diccionario


def test(imagenes, labels_prueba, _classifier, vectorizer, characters, windows, step, _range):
  # Extracción de palabras de las imágenes de prueba
  palabras_por_imagen, palabras_por_imagen_R, palabras_por_imagen_G, palabras_por_imagen_B = extract_words(imagenes, characters, windows, step, _range)
  print ('palabras_por_imagen', palabras_por_imagen[0])

  # Generación de histogramas de las imágenes de prueba
  histogramas_img_prueba = vectorizer.transform(palabras_por_imagen)

  print("antes de clasficador - test")
  predicciones = _classifier.predict(histogramas_img_prueba)

  return predicciones


def results(labels_prueba, predicciones):
  exactitud = accuracy_score(labels_prueba, predicciones)

  return exactitud


def experiment(_range, windows, step, imagenes_entrenamiento, labels_entrenamiento, imagenes_prueba, labels_prueba, characters):
  print("train...")
  _classifier, vectorizer, tam_diccionario = train(imagenes_entrenamiento, labels_entrenamiento, characters, windows, step, _range)
  print("test...")
  predicciones = test(imagenes_prueba, labels_prueba, _classifier, vectorizer, characters, windows, step, _range)
  exactitud = results(labels_prueba, predicciones)

  return exactitud, tam_diccionario

params_set = generate_configurations()
print(params_set)
characters = generate_characters()

########################################################### Lectura de imágenes ###########################################################
imagenes_entrenamiento, labels_entrenamiento =  read_images("train.txt")
print("Cantidad de imágenes de entrenamiento:",  len(imagenes_entrenamiento))
imagenes_prueba, labels_prueba =  read_images("test.txt")
print("Cantidad de imágenes de prueba:",  len(imagenes_prueba))

titulos = ["RANGO", "VENTANA", "STEP", "Exactitud", "Tamaño Alfabeto", "Tamaño Diccionario"] # Para imprimir en csv


with open(CSV_PATH,'w') as f:
  w = csv.writer(f)
  w.writerow(titulos)

  for param in params_set:
      _range = param.get("range")
      windows = param.get("windows")
      step = param.get("step")

      print(windows)

      tamAlfabeto = get_alphabet_size(characters, _range)
      exactitud, tam_diccionario = experiment(_range, windows, step, imagenes_entrenamiento, labels_entrenamiento, imagenes_prueba, labels_prueba, characters)
      w.writerow([_range, windows, step, exactitud, tamAlfabeto, tam_diccionario])

      resultados = "RANGO :" + str(_range) + " VENTANA :" + str(windows) + " STEP :" + str(step) + " exactitud : " + str(exactitud) + " tam_alfabeto : " + str(tamAlfabeto) + " tam_diccionario :" + str(tam_diccionario)
      print(colored(resultados, 'red'))